Non-automatic tests
=========================

(44 tests)

share-binary-and-unicode.py
    Run with ipython -i
    Open <http://localhost:5813/ctx/cow.jpg> and <http://localhost:5813/ctx/unicode.txt> in a browser
    In a terminal, run seamless-http-put <http://localhost:5813/ctx/cow.jpg> --upload-file cow-rotate.jpg --binary
    The cow should be upside down upon refresh
    In a terminal, run seamless-http-put <http://localhost:5813/ctx/unicode.txt> --upload-file unicode.txt
    The unicode text should change upon refresh
docker-kill.py    The output is not important. Important is that "docker ps -a" reveals no remaining orphaned "ubuntu" Docker containers.
bash-kill.py      The output is not important. Important is that the script finishes in ~4 sec, and that 'ps -ef' reveals no remaining orphaned "sleep" processes
add.py:           Run with ipython -i, then change mounts /tmp/a /tmp/b /tmp/c /tmp/code.py
simpler-share.py: Run with ipython -i, then do "curl localhost:5813/ctx/myresult".
                  IPython values printed should be 36 then 39 (Silk); curl should return 39
                  change ctx.a to get 3*a as the result
mount.py:         Run with ipython -i, then continue in interactive mode.
                  Initial output is in test-outputs/mount.out
cython_.py        Run with ipython -i
highlink-cpp.py:  Run with ipython -i, then continue in interactive mode,
                  changing the source code (/tmp/code.cpp)
                  Initial output is in test-outputs/highlink-cpp.out

imperative-*-async.py: Run with ipython -i -c '%load '$i'.py' and press enter

observe-graph.ipynb: Run "seamless-jupyter" and then open /cwd in the browser
observe-cpp: see above. Modify /tmp/test.cpp and /tmp/schema.json
traitlets.ipynb: same as above
share-subcontext.py: open with seamless-ipython -i, Open in <http://localhost:5813/ctx/sub/b>
share-pdb.py: open with seamless-ipython -i, Open in <http://localhost:5813/ctx/index.html>
share-pdb-docker.seamless/.zip: to test using:
      seamless-serve-graph share-pdb-docker.seamless \
      --load-zip share-pdb-docker.zip
    Open in <http://localhost:5813/ctx/index.html>
    Potentially, add --status-graph
    In that case, open also <http://localhost:5813/status/index.html>
    Potentially, add --delegate
parse-pdb.py: requires seamless database (delegation level 3)
              will fail unless parse-pdb-environment.yml is installed
              can be done in the seamless-bash Docker image,
              or in the Dask (local.py) environment when using the Dask assistant
              This can also be done a posteriori using seamless-run-transformation
               on the printed-out checksum
plotting.py. Change ctx.plot.period and ctx.plot.npoints.
environment.py
   Can be run automatically in a standard container (with python),
    and will exit at some point because Rust is not installed
    (see test-outputs/environment.out)
  Otherwise, install Rust in the container and then run the test.
  (Rust can be installed with "mamba install rust")
  This will print 29, 34, 34 at the end (see code)
environment2.py
   Can be run automatically in a standard container  (with python),
    and will exit at some point because Go is not installed
    (see test-outputs/environment2.out)
  Otherwise, install Go in the container and then run the test.
  (Go can be installed with "mamba install go-cgo")
  This will print "OK", 2029, 2096 at the end, and then wait for a debugger
  (not implemented for Go yet)
environment4.py
  This will fail.
  Install net-tools with apt and 'sympy==1.9.*' with conda/mamba to make it succeed.
environment5.py
  Loads and runs the graph for environment3 and then environment4.
  Should succeed for the former (result: 11.40)
   and fail for the latter.
  Install net-tools with apt and 'sympy==1.9.*' with conda to make it succeed.
environment6.py
  Adding dynamic support for PHP. This will fail.
  Install php-cli with apt and python-bond with pip to make it succeed.
r.py
  run with ipython
  Third line should be <Silk: 314.3% >
  There should be two plots, in:
   <http://localhost:5813/ctx/result.svg>
   and
   <http://localhost:5813/ctx/result.png>
  edit plot.R
  The PNG should update, the SVG should not

environment7.py: This will fail if executed without delegation or with the micro/mini-assistant,
  because pytorch is required. Regardless, the transformation checksum is printed out, and
  the dunder is written to file. In a standard Seamless environment,
  "seamless-run-transformation <checksum>" will return an error:
  "ModuleNotFoundError: No module named 'torch'"
  In contrast, "seamless-run-transformation.py <checksum> --dunder environment7-dunder.json"
  will validate the environment and give the same error message as the main script
  ("Conda package 'pytorch' not installed").
  Either syntax will succeed inside a proper environment
  (where both Seamless and PyTorch are available).

compute-ctrl-c.py: open with ipython, type "ctx.compute()" and press ctrl+c
delay-direct-print-file: open with ipython, monitor /tmp/direct-print.out, change ctx.tf1.a and ctx.tf1.delay
debugmode-py-light.py
  To debug a simple Python transformer in VSCode. Follow the instructions.
debugmode-compiled-light.py
  To debug a simple C++ transformer in VSCode. Follow the instructions.
debugmode-py-sandbox.py
  Sandbox debugging of a simple Python transformer in VSCode. Follow the instructions.
debugmode-pymodule-light.py
  To debug a Python transformer with Python single-file module in VSCode. Follow the instructions.
debugmode-pymodule-sandbox.py
  Sandbox debugging of a Python transformer with Python single-file module in VSCode. Follow the instructions.
debugmode-pypackage-light.py
  To debug a Python transformer with Python package in VSCode. Follow the instructions.
debugmode-compiledmodule-light.py
  To debug a multi-file C/C++ transformer in VSCode. Follow the instructions.
debugmode-compiled-sandbox.py
  Sandbox debugging of a simple C++ transformer in VSCode. Follow the instructions.
debugmode-compiledmodule-sandbox.py
  Sandbox debugging of a multi-file C/C++ transformer in VSCode. Follow the instructions.
debugmode-py-shell.py  
  Debug IPython shell for a Python transformer. Follow the instructions.
debugmode-bash-shell.py  
  Debug bash shell. Follow the instructions.
debugmode-docker-shell.py  
  Debug bash shell, with Docker image. Follow the instructions.
hack-bash-transformer-translation.py
  Run with IPython and hack /tmp/execute.py
  Monitor testctx.tf.logs
fallback-mount-share.py
  Run with IPython, modify /tmp/a and /tmp/b .
  This will *not* update ctx.a until you leave fallback mode
  Check "curl localhost:5813/ctx/a"
  Do:

- fctx.aa = ...
- ctx.translate(force=True)
- ctx.a.fallback(None)
- ctx.a.fallback(fctx.aa)
- fctx.translate(force=True)
imperative-manyjobs.py
  Needs to be run with a Dask cluster, 1000x ~20 sec jobs. Submitting 1000 jobs may take a few minutes. Will calculate pi to 6 digits. Expected results: 3.141593805644 5.116277454745302e-05 3.141592653589793
  Instead of 1000, the number of jobs can also be given as a command-line option
multi-core-transformations.py
  It is expected that job 1 finishes before job 2, and job 2 finishes after 7 seconds.
  With DELEGATE, run this with the micro Dask assistant and a local Dask cluster with --ncores 5
  Change ncores to 4 to have the first job fail, for a total duration of 2 seconds
  TODO: as of Seamless 0.12, the first job stays "ready" forever
  Change ncores to 6 to have both jobs execute in parallel. Job 2 will finish after 2.5 seconds,
   and job 1 will still be running.
   TODO: as of Seamless 0.12, the first job says "ready" instead of running
slow-buffer.py
  To detect suspected slowness issues with buffer upload, but hasn't given an error yet.
webserver-nested
  Run with:
     cd webserver-nested
     rm -rf vault web graph load-project.py webserver-nested.ipynb
     seamless-new-project webserver-nested
     in load-project.py, change DELEGATION_LEVEL to 4
     seamless-load-project
     %run -i history.py
     !cp webform-CUSTOM.json web/webform.json
     save()
     export()
  Version of manyjobs where the number of jobs is parametrized.
  Half of the jobs are calculated with the direct style (like imperative-manyjobs.py).
  The other half are calculated with the command-line style (like ../cmd/manyjobs.sh)
