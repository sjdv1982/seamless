# In general, run with:
#   python3 -u TEST.py > test-outputs/TEST.out 2>&1
#   Best also to test using "ipython3 TEST.py", since re-translation may work differently
#   Before each release, the test set must be run:
#   - under seamless-bash/seamless-run (within Docker)
#   - under seamless-framework (bare-metal conda)
jupyter.sh
bytecell.py
bytecell2.py
bytecell3.py
buffer_remote.sh
cachehit-semantic.py
conversions.py: the output is approximate, depends on exact timings
TODO?: simple.py: can be run with Seamless database (fresh), in which case the execution metadata is printed
simple-async.py
simple-indirect.py
simple-ipython.py
exception_upon_compute.py
subcontext.py
simple-reactor.py
downstream-reactor.py
reactor-edit.py
TODO: simple-cache.py: see instructions in file
plain.py
mixedcell.py
preliminary.py: the output is approximate, depends on exact timings
cached.py
mount-as-directory.py
structured_cell/simple-auth.py
structured_cell/simple-macro-mode.py
structured_cell/simple-channels.py
structured_cell/iadd.py
dummy-remote-buffercache.py
dummy-remote-result1.py
dummy-remote-result2.py
dummy-remote-result3.py
dummy-remote-result4.py
simplest-macro.py
simple-macro.py
compile.py
compile-fortran.py
compile-mixedlang.py
schema.py
fingertip.py
TODO?: reuse.sh: run with Seamless database (fresh db file).
TODO?: reuse-compile.sh: run with Seamless database (fresh db file).
injection.py
dependent-modules.py
module-package.py
module-package-complex.py
module-package-absolute.py
injection2.py
injection3.py
injection4.py: the output is approximate, depends on exact timings, see also [1]
injection5.py: see above
simple-share.py
TODO?: transformation-checksum.sh: run with Seamless database. If not in the Docker image, set SEAMLESS_SCRIPT_DIR
transformation-raw.py
transformation-raw-ipython.py
transformation-raw-bash.py
transformation-raw-bashdocker.py: can be run with delegation using "export DELEGATE=''"
meta.py
simple-duplex.py
TODO: simple-remote.py: run together with seamless-jobslave
TODO: simple-remote2.py: run together with:
     seamless-jobslave jobslave --direct-print
     after the run:
     docker logs jobslave > test-outputs/simple-remote2-jobslave.out 2>&1
TODO: simple-duplex-remote.py: run together with:
     seamless-jobslave jobslave --direct-print
     after the run:
     docker logs jobslave > test-outputs/simple-duplex-remote-jobslave.out 2>&1
TODO: compile-run-remote.py: 
     seamless-jobslave jobslave --direct-print
     after the run:
     docker logs jobslave, should include "ADD 8.141592979431152"
structured_cell/scratch.sh: run as i=structured_cell/scratch; seamless-bash ./$i.sh > test-outputs/$i.out 2>&1
     make sure that level 3 delegation is available inside a clean buffer directory and database.
structured_cell/scratch2.sh: run as i=structured_cell/scratch2; seamless-bash ./$i.sh > test-outputs/$i.out 2>&1
     make sure that level 3 delegation is available inside a clean buffer directory and database.
scratch-transformer.sh: run as i=scratch-transformer; seamless-bash ./$i.sh > test-outputs/$i.out 2>&1
     make sure that level 3 delegation is available inside a clean buffer directory and database.
macro.py
macro2.py
macro3.py
pin-as.py
TODO?: pin-filesystem.sh: run as i=pin-filesystem; seamless-bash ./$i.sh > test-outputs/$i.out 2>&1
  Make sure that the database is not running
  If not in the Docker image, set SEAMLESS_TOOLS_DIR to <seamless-tools-git>/tools
checksum-cell.py
structured_cell/simple-deepcell.py
structured_cell/simple-deepcell-rawbuffer.py
structured_cell/channels-deepcell.py
structured_cell/schema.py
structured_cell/schema-deepcell.py
structured_cell/channels-morph.py
deepcell-transform.py
collatz.py: the output is approximate, depends on exact timings
structured_cell/preliminary.py: the output is approximate, depends on exact timings

Non-automatic tests
=========================
mount.py:
     - remove /tmp/mount-test
     - run with ipython3 -i
     - then open all files in /tmp/mount-test and manipulate/monitor them
mount-direct.py: see above
mount-cson.py:
     - remove /tmp/test.cson and /tmp/test.json
     - run with ipython3 -i
     - then open /tmp/test.cson and /tmp/test.json, manipulate resp. monitor them
mount-plain.py: see above, minus the .cson

TODO: simple-communion: 
     do 
     In one terminal, run:
     export SEAMLESS_DOCKER_PUBLISH_SHARESERVER_PORTS='-p 8602:8602'
     seamless-bash
     python3 -u simple-communion-slave.py > test-outputs/simple-communion-slave.out 2>&1
     then, in a different terminal, run:
     seamless-bash
     python3 -u simple-communion-master.py > test-outputs/simple-communion-master.out 2>&1
     then Ctrl-C simple-communion-slave.py
     The output is available in simple-communion-[master/slave].out
simple-debug.py: Run in Visual Studio Code 
  Will work only under bare metal (not in Docker).
  Can't set breakpoints.
mount.ipynb
TODO: communion-peer[12].sh: 
     In one terminal, run:
     export SEAMLESS_DOCKER_PUBLISH_SHARESERVER_PORTS='-p 8601:8601'
     seamless-bash
     ./communion-peer1.sh > test-outputs/communion-peer1.out 2>&1
     In another seamless-bash terminal, run:
     (if not inside Docker, first do "export SEAMLESS_DOCKER_HOST_IP=localhost")"
     ./communion-peer2.sh > test-outputs/communion-peer2.out 2>&1
     then Ctrl-C communion-peer1.sh
     The output is available in communion-peer[12].out
compile-debug.py
     - Run with ipython3 -i . 
       Run gdb from a second shell into the container. 
     To make this work, you will need to do one of the following:
     - run the gdb shell as privileged root, i.e. as "docker exec -u root -it --privileged container_name bash"
     OR
     - disable kernel hardening in your host (/proc/sys/kernel/yama/ptrace_scope, set the value to 0)
     In GDB:
       attach to the process.
       Type "break addfunc", then "signal SIGUSR1" .
       Type "step", "print(a)", and "cont" (2x)
     print(a) will show 2.
     Afterwards, you will see "ADD 8.141592979431152" in Seamless.
transformation-raw-conda.py
     First run this, and it should give an error
     then install Tensorflow with "pip install tensorflow", and then it should work 
     Make sure that "conda list -f tensorflow" works correctly.

NOTES
=====
[1] This test is about Cython and can also run non-automatically.
- Run with ipython3 -i
- Open cell-ipython.html in the browser and cell-ipython*.ipy in a text editor
- Interpolate cell-ipython.ipy between ORIGINAL and OPTIMIZED,
  and observe the HTML and timings.
