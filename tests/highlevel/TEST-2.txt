get-file-and-directory.sh
imperative-async.sh
imperative-async-parallel-jupyter.sh: can be run with delegation using "export DELEGATE=''"
macro-elision-database.sh: 
pin-filesystem.sh:

set-python-invalid.py: can also be run in interactive mode (mount /tmp/code.py)
deepcell-filter: can also be run in interactive mode (mount /tmp/blacklist.json, /tmp/filt_cell.json)
folder : writes data in ./testfolder
folder2 : assumes that folder.py has been run
simpler-python.py: Run with ipython --no-term-title (not -i) (see issue 25). Output is approximate, depends on exact timings.
  run as i=macro-elision-database; seamless-run ./$i.sh > test-outputs/$i.out 2>&1
  If not in the Docker image, set SEAMLESS_TOOLS_DIR to <seamless-tools-git>/tools
multi-module: can also be run in interactive mode (see instructions in file)
moduleaccess.py: can also be run in interactive mode (mount /tmp/module.py)
docker_: can be run with delegation using "export DELEGATE=''"
docker_gpu: run only on a machine with nvidia-docker2 installed
docker-singularity: needs singularity set up
traitlet2: The exact output is dependent on random memory locations
simple: can be run with level 3 delegation using "export DELEGATE=''"
simple-pi: Also creates twopi.seamless, twopi-result.seamless, twopi-result.zip
simple-pi-deepcell: Also creates twopi-deepcell.seamless, twopi-deepcell-result.seamless, twopi-deepcell-result.zip
simple-pi-remote: run with an assistant
transformer-compiled: can be run with delegation using "export DELEGATE=''"
twopi-graph-database.sh: run with Seamless database
                      first delete job results: rm -rf /tmp/seamless-db
                      then: seamless-database twopi-graph-database.yaml
                      run as i=twopi-graph-database; seamless-run ./$i.sh > test-outputs/$i.out 2>&1
twopi-graph-jobmaster.sh: same as above; run as i=twopi-graph-jobmaster
  Run this in an environment where seamless-upload is available
  run as i=pin-filesystem; ./$i.sh > test-outputs/$i.out 2>&1
reuse-compile.sh: run with Seamless database
test-fingertip.sh: run with Seamless database
vault.bash: run as i=vault; seamless-run ./$i.bash > test-outputs/$i.out 2>&1
bind-status: can also be run in interactive mode, run with "ipython3 -i", make modifications and type "report" and monitor /tmp/graph.json and /tmp/status.json
undo: requires delegation level 3. Can be run with full delegation using "export DELEGATE=''", but this requires the mini-assistant or better.
imperative-undo: requires delegation level 3
imperative-async-parallel: can be run with delegation using "export DELEGATE=''"
imperative-async-parallel-jupyter.sh: can be run with delegation using "export DELEGATE=''"
imperative-nested: FULL DELEGATION NOT WORKING. requires delegation level 3. Can be run with full delegation using "export DELEGATE=''". 
imperative-nested-jupyter.sh: requires delegation level 3.
imperative-nested-async.sh: requires delegation level 3.
imperative-database: run with Seamless database and buffer dir, preferably in a clean setup
imperative-database-async.sh: run with Seamless database and buffer dir, preferably in a clean setup
imperative-delegated: FULL DELEGATION NOT WORKING. requires full delegation. 
imperative-delegated-slow: requires full delegation. Set SEAMLESS_ASSISTANT_JOB_TIMEOUT to 15 in order to test client 202 capacity.
imperative-delegated-async.sh: requires full delegation
imperative-delegated-nonlocal: requires nested delegation. Does not currently work, see (https://github.com/sjdv1982/seamless/issues/217)
imperative-module: requires delegation level 3, definitely in a clean setup. Can be run with full delegation using "export DELEGATE=''"
imperative-scratch: requires delegation level 3, definitely in a clean setup
environment7: requires full delegation. micro-assistant will not work out-of-the-box. Can also be run non-automatically, see below.
imperative-environment: Will take ~15 minutes to run (faster if GPU available). Requires full delegation. micro-assistant will not work out-of-the-box
environment7a: version of environment7 where the conda environment name is specified. Will work with the mini-assistant if the environment "pytorch-seamless" is present 
environment7b: version of environment7 where the Docker image name is specified. Will work with the mini-assistant if the Docker image "seamless-devel-pytorch" is present, which can be built using environment7b.Dockerfile
eager: FAILS as of 0.7 (https://github.com/sjdv1982/seamless/issues/90)
help: Can also be run interactively with IPython. See the source code for mounts and shares
webinterface.sh: open with bash inside the Seamless Docker container.
                 Can also be run interactively, see line 6 of the code
meta-local: 1. run without jobless/jobslave:                        #1 succeed, #2 fail, #3 fail
            2. run with --communion and a jobslave:                 #1 succeed, #2 succeed, #3 succeed
                See test-outputs/meta-local.log
            3. run with --communion --database and jobless:         #1 succeed, #2 succeed, #3 fail
            Database can be cleaned with: 
              seamless-delete-database-from-log test-outputs/meta-local.log
              (outside the Docker container)
             python3 ~/seamless-scripts/delete-database-from-log.py test-outputs/meta-local.log
              (inside the Docker container)
deepcell-pdb: requires a FAIR server that knows the PDB dataset
                 Can also be run interactively, change ctx.pdb_code 
                  and observe /tmp/pdb_structure.mmcif
deepfolder-pdb: See above . change ctx.pdb_code to "1wej.cif", "1brs.cif" or "7cei.cif" 
                Also, /tmp/pdb_folder will contain 1brs.cif, 1wej.cif and 7cei.cif.
high-in-low4-memory    # Quite long test.
                          # Creates 5.6 GB of buffer cache in /tmp/dummy-db
                          # Run with rm -rf /tmp/dummy-db  && mkdir -p /tmp/dummy-db && seamless-database dummydb-config.yaml
                          # Time is ~100 seconds, or ~60 seconds when re-executed
                          # Re-executing the test is faster, because the transformation results and input buffers are cached
                          # Exact output will depend on timings
                          # After the test, "rm -rf /tmp/dummy-db && docker stop seamless-database-container"
high-in-low6-memory    # See above. Time is ~60 seconds, or ~35 seconds when re-executed
map-speed-test: long test, calculates the speed of stdlib.map_dict
map-speed-test2: long test, calculates the speed of stdlib.map_dict_chunk
  This test takes 10-20 minutes
  Need to choose a version (non-reproducibility issue)
    Both versions built using seamless-tools/build-devel-env.sh, seamless-tools commit 22823492f5ab42a5cfb77fc030fcfc126b5d2907
    version 1: 
      Intel Xeon Skylake, Ubuntu 18.04
      Supported SIMD extensions in this NumPy install:
        baseline = SSE,SSE2,SSE3
        found = SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,FMA3,AVX2,AVX512F,AVX512CD,AVX512_SKX
        not found = AVX512_CLX,AVX512_CNL,AVX512_ICL
    version 2:
      Intel i5-1235U, Ubuntu 22.04
      Supported SIMD extensions in this NumPy install:
          baseline = SSE,SSE2,SSE3
          found = SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,FMA3,AVX2
          not found = AVX512F,AVX512CD,AVX512_SKX,AVX512_CLX,AVX512_CNL,AVX512_ICL    
  (Using NPY_DISABLE_CPU_FEATURES does not have an effect)  
   run as "cd scratch-provenance/version; ./run.sh". Requires delegation to be startable from command line ("seamless-delegate" etc. must be available)
Non-automatic tests
    Run with python -i
    Open http://localhost:5813/ctx/cow.jpg and http://localhost:5813/ctx/unicode.txt in a browser
    In a terminal, run seamless-http-put http://localhost:5813/ctx/cow.jpg --upload-file cow-rotate.jpg --binary
    The cow should be upside down
    In a terminal, run seamless-http-put http://localhost:5813/ctx/unicode.txt --upload-file unicode.txt
    The unicode text should refresh
docker-kill    The output is not important. Important is that "docker ps -a" reveals no remaining orphaned "ubuntu" Docker containers.
bash-kill      The output is not important. Important is that the script finishes in 3.5-4 sec, and that 'ps -ef' reveals no remaining orphaned "sleep" processes
add:           Run with ipython -i, then change mounts /tmp/a /tmp/b /tmp/c /tmp/code.py
simpler-share: Run with ipython -i, then do "curl localhost:5813/ctx/myresult".
                  IPython values printed should be 36 then 39 (Silk); curl should return 39
                  change ctx.a to get 3*a as the result
highlink-cpp:  Run with ipython -i, then continue in interactive mode,
                  changing the source code and the schema until it works.
mount:         Run with ipython -i, then continue in interactive mode.
                  Initial output is in test-outputs/mount.out
cython_        Run with ipython -i                 
imperative-*-async: Run with ipython -i -c '%load '$i'.py' and press enter
scratch.sh: make sure that level 3 delegation is available inside a clean buffer directory and database.
observe-graph.nb: Run "seamless-jupyter" and then open /cwd in the browser
observe-cpp.ipynb
traitlets.nb: same as above
share-subcontext: open with seamless-ipython -i, Open in http://localhost:5813/ctx/sub/b
share-pdb: open with seamless-ipython -i, Open in http://localhost:5813/ctx/index.html
share-pdb-docker.seamless/.zip: to test using:
      seamless-serve-graph share-pdb-docker.seamless \
      --load-zip share-pdb-docker.zip
    Open in http://localhost:5813/ctx/index.html
    Potentially, add --status-graph
    In that case, open also http://localhost:5813/status/index.html
parse-pdb: requires seamless database.
              will fail unless parse-pdb-environment.yml is installed
              can be done when running the test, or afterwards using:
               # set up delegation
               cs=...  # parse from initial output
               seamless-run-transformation $cs
               seamless-conda-env-modify SOMEDIR parse-pdb-environment.yml
               (seamless-conda-env-modify must be run outside the container)
               seamless-conda-env-run-transformation SOMEDIR $cs
plotting. Change ctx.plot.period and ctx.plot.npoints.
   Can be run automatically in a standard container (withthon),
    and will exit at some point because Rust is not installed
    (see test-outputs/environment.out)
  Otherwise, install Rust in the container and then run the test.
  (Rust can be installed with "mamba install rust")
  This will print 29, 34, 34 at the end (see code)
   Can be run automatically in a standard container  (withthon),
    and will exit at some point because Go is not installed
    (see test-outputs/environment2.out)
  Otherwise, install Go in the container and then run the test.
  (Go can be installed with "mamba install go-cgo")
  This will print "OK", 2029, 2096 at the end, and then wait for a debugger 
  (not implemented for Go yet)
  This will fail. 
  Install net-tools with apt and 'sy==1.7.*' with conda/mamba to make it succeed.
  Loads and runs the graph for environment3 and then environment4.
  Should succeed for the former (result: 11.40)
   and fail for the latter.
  Install net-tools with apt and 'sy==1.7.*' with conda to make it succeed.
  Adding dynamic support for PHP. This will fail. 
  Install php7.4-cli with apt andthon-bond with pip to make it succeed.
  run with python
  Third line should be <Silk: 314.3% >
  There should be two plots, in:
  edit plot.R
  The PNG should update, the SVG should not
environment7: This will fail if executed without delegation or with the micro-assistant,
becausetorch is required. Regardless, the transformation checksum is printed out, and
the dunder is written to file. In a standard Seamless environment, 
"run-transformation <checksum>" will return an error: 
"ModuleNotFoundError: No module named 'torch'"
In contrast, "run-transformation <checksum> environment7-dunder.json" 
will validate the environment and give the same error message as the main script
("Conda package torch' not installed"). 
Either syntax will succeed inside a proper environment 
(where both Seamless and PyTorch are available).
compute-ctrl-c: open with ipython, type "ctx.compute()" and press ctrl+c
delay-direct-print-file: open with python, monitor /tmp/direct-print.out, change ctx.tf1.a and ctx.tf1.delay
  To debug a simple Python transformer in VSCode. Follow the instructions.
  To debug a simple C++ transformer in VSCode. Follow the instructions.
  Sandbox debugging of a simple Python transformer in VSCode. Follow the instructions.
  To debug a Python transformer with Python single-file module in VSCode. Follow the instructions.
  Sandbox debugging of a Python transformer with Python single-file module in VSCode. Follow the instructions.
  To debug a Python transformer with Python package in VSCode. Follow the instructions.
  To debug a multi-file C/C++ transformer in VSCode. Follow the instructions.
  Sandbox debugging of a simple C++ transformer in VSCode. Follow the instructions.
  Sandbox debugging of a multi-file C/C++ transformer in VSCode. Follow the instructions.
  Debug IPython shell for a Python transformer. Follow the instructions.
  Debug bash shell. Follow the instructions.
  Debug bash shell, with Docker image. Follow the instructions.
  Run with IPython and hack /tmp/execute
  Run with IPython, modify /tmp/a and /tmp/b . 
  This will *not* update ctx.a until you leave fallback mode
  Check "curl localhost:5813/ctx/a"
  - fctx.aa = ...
  - ctx.translate(force=True)
  - ctx.a.fallback(None)
  - ctx.a.fallback(fctx.aa)
  - fctx.translate(force=True)
  Needs to be run with a Dask cluster, 1000x ~20 sec jobs. Submitting 1000 jobs may take a few minutes. Will calculate pi to 6 digits. Expected results: 3.141593805644 5.116277454745302e-05 3.141592653589793
  It is expected that job 1 finishes before job 2, and job 2 finishes after 7 seconds.
  With DELEGATE, run this with a local Dask cluster with --ncores 5
  Change ncores to 4 to have the first job fail, for a total duration of 2 seconds
  Change ncores to 6 to have both jobs execute in parallel. Job 2 will finish after 2.5 seconds,
   and job 1 will still be running.
  To detect suspected slowness issues with buffer upload, but hasn't given an error yet.

scratch-provenance: 
  This test takes 10-20 minutes
  Need to choose a version (non-reproducibility issue)
    Both versions built using seamless-tools/build-devel-env.sh, seamless-tools commit 22823492f5ab42a5cfb77fc030fcfc126b5d2907
    version 1: 
      Intel Xeon Skylake, Ubuntu 18.04
      Supported SIMD extensions in this NumPy install:
        baseline = SSE,SSE2,SSE3
        found = SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,FMA3,AVX2,AVX512F,AVX512CD,AVX512_SKX
        not found = AVX512_CLX,AVX512_CNL,AVX512_ICL
    version 2:
      Intel i5-1235U, Ubuntu 22.04
      Supported SIMD extensions in this NumPy install:
          baseline = SSE,SSE2,SSE3
          found = SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,FMA3,AVX2
          not found = AVX512F,AVX512CD,AVX512_SKX,AVX512_CLX,AVX512_CNL,AVX512_ICL    
  (Using NPY_DISABLE_CPU_FEATURES does not have an effect)  
   run as "cd scratch-provenance/version; ./run.sh". Requires delegation to be startable from command line ("seamless-delegate" etc. must be available)

Non-automatic tests
=========================
share-binary-and-unicode.py
    Run with ipython -i
    Open http://localhost:5813/ctx/cow.jpg and http://localhost:5813/ctx/unicode.txt in a browser
    In a terminal, run seamless-http-put http://localhost:5813/ctx/cow.jpg --upload-file cow-rotate.jpg --binary
    The cow should be upside down
    In a terminal, run seamless-http-put http://localhost:5813/ctx/unicode.txt --upload-file unicode.txt
    The unicode text should refresh
docker-kill.py    The output is not important. Important is that "docker ps -a" reveals no remaining orphaned "ubuntu" Docker containers.
bash-kill.py      The output is not important. Important is that the script finishes in 3.5-4 sec, and that 'ps -ef' reveals no remaining orphaned "sleep" processes
add.py:           Run with ipython -i, then change mounts /tmp/a /tmp/b /tmp/c /tmp/code.py
simpler-share.py: Run with ipython -i, then do "curl localhost:5813/ctx/myresult".
                  IPython values printed should be 36 then 39 (Silk); curl should return 39
                  change ctx.a to get 3*a as the result
highlink-cpp.py:  Run with ipython -i, then continue in interactive mode,
                  changing the source code and the schema until it works.
mount.py:         Run with ipython -i, then continue in interactive mode.
                  Initial output is in test-outputs/mount.out
cython_.py        Run with ipython -i                 

imperative-*-async.py: Run with ipython -i -c '%load '$i'.py' and press enter
scratch.sh: make sure that level 3 delegation is available inside a clean buffer directory and database.

observe-graph.ipynb: Run "seamless-jupyter" and then open /cwd in the browser
traitlets.ipynb: same as above
share-subcontext.py: open with seamless-ipython -i, Open in http://localhost:5813/ctx/sub/b
share-pdb.py: open with seamless-ipython -i, Open in http://localhost:5813/ctx/index.html
share-pdb-docker.seamless/.zip: to test using:
      seamless-serve-graph share-pdb-docker.seamless \
      --load-zip share-pdb-docker.zip
    Open in http://localhost:5813/ctx/index.html
    Potentially, add --status-graph
    In that case, open also http://localhost:5813/status/index.html
parse-pdb.py: requires seamless database.
              will fail unless parse-pdb-environment.yml is installed
              can be done when running the test, or afterwards using:
               cs=...  # parse from initial output
               seamless-conda-env-export SOMEDIR
               seamless-conda-env-modify SOMEDIR parse-pdb-environment.yml
               (seamless-conda-env-modify must be run outside the container)
               seamless-conda-env-run-transformation SOMEDIR $cs
plotting.py. Change ctx.plot.period and ctx.plot.npoints.
environment.py
   Can be run automatically in a standard container (with python),
    and will exit at some point because Rust is not installed
    (see test-outputs/environment.out)
  Otherwise, install Rust in the container and then run the test.
  (Rust can be installed with "mamba install rust")
  This will print 29, 34, 34 at the end (see code)
environment2.py
   Can be run automatically in a standard container  (with python),
    and will exit at some point because Go is not installed
    (see test-outputs/environment2.out)
  Otherwise, install Go in the container and then run the test.
  (Go can be installed with "mamba install go-cgo")
  This will print "OK", 2029, 2096 at the end, and then wait for a debugger 
  (not implemented for Go yet)
environment4.py
  This will fail. 
  Install net-tools with apt and 'sympy==1.7.*' with conda/mamba to make it succeed.
environment5.py
  Loads and runs the graph for environment3 and then environment4.
  Should succeed for the former (result: 11.40)
   and fail for the latter.
  Install net-tools with apt and 'sympy==1.7.*' with conda to make it succeed.
environment6.py
  Adding dynamic support for PHP. This will fail. 
  Install php7.4-cli with apt and python-bond with pip to make it succeed.
r.py
  run with ipython
  Third line should be <Silk: 314.3% >
  There should be two plots, in:
   http://localhost:5813/ctx/result.svg
   and
   http://localhost:5813/ctx/result.png
  edit plot.R
  The PNG should update, the SVG should not

environment7.py: This will fail if executed without delegation or with the micro-assistant,
because pytorch is required. Regardless, the transformation checksum is printed out, and
the dunder is written to file. In a standard Seamless environment, 
"run-transformation.py <checksum>" will return an error: 
"ModuleNotFoundError: No module named 'torch'"
In contrast, "run-transformation.py <checksum> environment7-dunder.json" 
will validate the environment and give the same error message as the main script
("Conda package 'pytorch' not installed"). 
Either syntax will succeed inside a proper environment 
(where both Seamless and PyTorch are available).

compute-ctrl-c.py: open with ipython, type "ctx.compute()" and press ctrl+c
delay-direct-print-file: open with ipython, monitor /tmp/direct-print.out, change ctx.tf1.a and ctx.tf1.delay
debugmode-py-light.py
  To debug a simple Python transformer in VSCode. Follow the instructions.
debugmode-compiled-light.py
  To debug a simple C++ transformer in VSCode. Follow the instructions.
debugmode-py-sandbox.py
  Sandbox debugging of a simple Python transformer in VSCode. Follow the instructions.
debugmode-pymodule-light.py
  To debug a Python transformer with Python single-file module in VSCode. Follow the instructions.
debugmode-pymodule-sandbox.py
  Sandbox debugging of a Python transformer with Python single-file module in VSCode. Follow the instructions.
debugmode-pypackage-light.py
  To debug a Python transformer with Python package in VSCode. Follow the instructions.
debugmode-compiledmodule-light.py
  To debug a multi-file C/C++ transformer in VSCode. Follow the instructions.
debugmode-compiled-sandbox.py
  Sandbox debugging of a simple C++ transformer in VSCode. Follow the instructions.
debugmode-compiledmodule-sandbox.py
  Sandbox debugging of a multi-file C/C++ transformer in VSCode. Follow the instructions.
debugmode-py-shell.py  
  Debug IPython shell for a Python transformer. Follow the instructions.
debugmode-bash-shell.py  
  Debug bash shell. Follow the instructions.
debugmode-docker-shell.py  
  Debug bash shell, with Docker image. Follow the instructions.
hack-bash-transformer-translation.py
  Run with IPython and hack /tmp/execute.py
fallback-mount-share.py
  Run with IPython, modify /tmp/a and /tmp/b . 
  This will *not* update ctx.a until you leave fallback mode
  Check "curl localhost:5813/ctx/a"
  Do:
  - fctx.aa = ...
  - ctx.translate(force=True)
  - ctx.a.fallback(None)
  - ctx.a.fallback(fctx.aa)
  - fctx.translate(force=True)
imperative-manyjobs.py
  Needs to be run with a Dask cluster, 1000x ~20 sec jobs. Submitting 1000 jobs may take a few minutes. Will calculate pi to 6 digits. Expected results: 3.141593805644 5.116277454745302e-05 3.141592653589793
multi-core-transformations.py
  It is expected that job 1 finishes before job 2, and job 2 finishes after 7 seconds.
  With DELEGATE, run this with a local Dask cluster with --ncores 5
  Change ncores to 4 to have the first job fail, for a total duration of 2 seconds
  Change ncores to 6 to have both jobs execute in parallel. Job 2 will finish after 2.5 seconds,
   and job 1 will still be running.
slow-buffer.py
  To detect suspected slowness issues with buffer upload, but hasn't given an error yet.